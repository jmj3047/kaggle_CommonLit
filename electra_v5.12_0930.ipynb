{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n# from transformers import BertTokenizer, BertModel\n# from transformers import ElectraTokenizer, ElectraModel\n\nfrom transformers import ElectraTokenizer, ElectraModel, ElectraForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm  # Import tqdm for the progress bar","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:13.294339Z","iopub.execute_input":"2023-09-29T00:23:13.294840Z","iopub.status.idle":"2023-09-29T00:23:25.104708Z","shell.execute_reply.started":"2023-09-29T00:23:13.294808Z","shell.execute_reply":"2023-09-29T00:23:25.103522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:25.106916Z","iopub.execute_input":"2023-09-29T00:23:25.107318Z","iopub.status.idle":"2023-09-29T00:23:25.113623Z","shell.execute_reply.started":"2023-09-29T00:23:25.107281Z","shell.execute_reply":"2023-09-29T00:23:25.112432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:25.115572Z","iopub.execute_input":"2023-09-29T00:23:25.116323Z","iopub.status.idle":"2023-09-29T00:23:25.230773Z","shell.execute_reply.started":"2023-09-29T00:23:25.116285Z","shell.execute_reply":"2023-09-29T00:23:25.229718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-generator')\ntokenizer = ElectraTokenizer.from_pretrained('/kaggle/input/electra/base-discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:25.233758Z","iopub.execute_input":"2023-09-29T00:23:25.234196Z","iopub.status.idle":"2023-09-29T00:23:25.313037Z","shell.execute_reply.started":"2023-09-29T00:23:25.234148Z","shell.execute_reply":"2023-09-29T00:23:25.312019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 512 #Use 512 for better results (if using GPU)\n\ndef tokenize_text(text):\n    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n\ndata['text_tokens'] = data['text'].apply(tokenize_text)\n\n# Split the data into features and targets\nX = data['text_tokens'].tolist()\ny = data[['wording', 'content']].values\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train).to(device)\nX_test = torch.tensor(X_test).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:25.314449Z","iopub.execute_input":"2023-09-29T00:23:25.314855Z","iopub.status.idle":"2023-09-29T00:23:55.720292Z","shell.execute_reply.started":"2023-09-29T00:23:25.314819Z","shell.execute_reply":"2023-09-29T00:23:55.719152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = ElectraModel.from_pretrained('google/electra-base-generator').to(device)\nbase_model = ElectraModel.from_pretrained('/kaggle/input/electra/base-discriminator').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:23:55.721743Z","iopub.execute_input":"2023-09-29T00:23:55.722207Z","iopub.status.idle":"2023-09-29T00:24:00.848042Z","shell.execute_reply.started":"2023-09-29T00:23:55.722172Z","shell.execute_reply":"2023-09-29T00:24:00.846850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_bert_embeddings(text_tokens):\n    embeddings_list = []\n    with tqdm(total=len(text_tokens)) as pbar:\n        with torch.no_grad():\n            for tokens in text_tokens:\n                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n                embeddings_list.append(embeddings)\n                pbar.update(1)\n        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n        return embeddings_tensor\n\nX_train_embeddings = generate_bert_embeddings(X_train)\nX_test_embeddings = generate_bert_embeddings(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:24:00.850140Z","iopub.execute_input":"2023-09-29T00:24:00.850527Z","iopub.status.idle":"2023-09-29T00:26:15.868363Z","shell.execute_reply.started":"2023-09-29T00:24:00.850493Z","shell.execute_reply":"2023-09-29T00:26:15.864209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RegressionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \n#Defining a MCRMSE\ndef mean_columnwise_rmse(y_pred, y_true):\n    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n    return torch.mean(columnwise_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.871294Z","iopub.status.idle":"2023-09-29T00:26:15.874263Z","shell.execute_reply.started":"2023-09-29T00:26:15.873925Z","shell.execute_reply":"2023-09-29T00:26:15.873963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = base_model.config.hidden_size\nhidden_dim = 256  # Adjust the hidden layer dimension as needed\noutput_dim = 2  # Number of target variables\nmodel = RegressionModel(input_dim, hidden_dim, output_dim).to(device) ## 여기를 electra로 바꾸기\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 100 # Run it for 100-150 epoch, 보통 40으로 하면 3-4시간 걸림\nbatch_size = 128 # 64 or 128 if using GPU, 일렉트라로 돌리면 너무 큼. 16으로 해보기\n\ntrain_dataset = TensorDataset(X_train_embeddings, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_loss1_list = []\ntrain_loss2_list = []\ntest_loss1_list = []\ntest_loss2_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.877370Z","iopub.status.idle":"2023-09-29T00:26:15.880320Z","shell.execute_reply.started":"2023-09-29T00:26:15.880057Z","shell.execute_reply":"2023-09-29T00:26:15.880083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss_wording = 0\n    total_loss_content = 0\n    total_loss = 0\n    \n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n        loss_content = criterion(outputs[:, 1], targets[:, 1])\n\n        loss = (loss_wording + loss_content) / 2\n        loss.backward()\n        optimizer.step()\n        \n        total_loss_wording += loss_wording.item()\n        total_loss_content += loss_content.item()\n\n        total_loss += loss.item()\n        \n    train_loss1_list.append(total_loss_wording / len(train_loader))\n    train_loss2_list.append(total_loss_content / len(train_loader))\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n    \n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(X_test_embeddings)\n        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n        \n    test_loss1_list.append(test_loss1.item())\n    test_loss2_list.append(test_loss2.item())\n    \n    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.884513Z","iopub.status.idle":"2023-09-29T00:26:15.885348Z","shell.execute_reply.started":"2023-09-29T00:26:15.885090Z","shell.execute_reply":"2023-09-29T00:26:15.885114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loss1_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.886908Z","iopub.status.idle":"2023-09-29T00:26:15.887743Z","shell.execute_reply.started":"2023-09-29T00:26:15.887473Z","shell.execute_reply":"2023-09-29T00:26:15.887498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_data = {\n    'Epoch': list(range(1, len(train_loss1_list)+1)),\n    'Train_Loss_Wording': train_loss1_list,\n    'Train_Loss_Content': train_loss2_list,\n    'Test_Loss_Wording': test_loss1_list,\n    'Test_Loss_Content': test_loss2_list\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.895865Z","iopub.status.idle":"2023-09-29T00:26:15.896769Z","shell.execute_reply.started":"2023-09-29T00:26:15.896467Z","shell.execute_reply":"2023-09-29T00:26:15.896494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df = pd.DataFrame(loss_data)\n# loss_df.to_csv('losses.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.898233Z","iopub.status.idle":"2023-09-29T00:26:15.899029Z","shell.execute_reply.started":"2023-09-29T00:26:15.898770Z","shell.execute_reply":"2023-09-29T00:26:15.898794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_data['text_tokens'] = test_data['text'].apply(tokenize_text)\ntest_text_tokens = test_data['text_tokens'].tolist()\ntest_text_tokens = torch.tensor(test_text_tokens).to(device)\ntest_data_embeddings = generate_bert_embeddings(test_text_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.900485Z","iopub.status.idle":"2023-09-29T00:26:15.901311Z","shell.execute_reply.started":"2023-09-29T00:26:15.901060Z","shell.execute_reply":"2023-09-29T00:26:15.901085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict scores for test data\nmodel.eval()  # Set the model in evaluation mode\nwith torch.no_grad():\n    test_outputs = model(test_data_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.902821Z","iopub.status.idle":"2023-09-29T00:26:15.903657Z","shell.execute_reply.started":"2023-09-29T00:26:15.903398Z","shell.execute_reply":"2023-09-29T00:26:15.903423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.905164Z","iopub.status.idle":"2023-09-29T00:26:15.912057Z","shell.execute_reply.started":"2023-09-29T00:26:15.911763Z","shell.execute_reply":"2023-09-29T00:26:15.911787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['student_id'] = test_data['student_id']\nsubmission_df['content'] = test_outputs[:, 1].cpu()\nsubmission_df['wording'] = test_outputs[:, 0].cpu()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.913542Z","iopub.status.idle":"2023-09-29T00:26:15.914383Z","shell.execute_reply.started":"2023-09-29T00:26:15.914126Z","shell.execute_reply":"2023-09-29T00:26:15.914151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T00:26:15.915835Z","iopub.status.idle":"2023-09-29T00:26:15.916648Z","shell.execute_reply.started":"2023-09-29T00:26:15.916395Z","shell.execute_reply":"2023-09-29T00:26:15.916419Z"},"trusted":true},"execution_count":null,"outputs":[]}]}