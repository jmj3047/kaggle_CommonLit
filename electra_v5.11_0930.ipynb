{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n# from transformers import BertTokenizer, BertModel\n# from transformers import ElectraTokenizer, ElectraModel\n\nfrom transformers import ElectraTokenizer, ElectraModel, ElectraForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm  # Import tqdm for the progress bar","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:43:55.719646Z","iopub.execute_input":"2023-09-28T15:43:55.720129Z","iopub.status.idle":"2023-09-28T15:43:55.728620Z","shell.execute_reply.started":"2023-09-28T15:43:55.720081Z","shell.execute_reply":"2023-09-28T15:43:55.727644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:43:55.730756Z","iopub.execute_input":"2023-09-28T15:43:55.731386Z","iopub.status.idle":"2023-09-28T15:43:55.750828Z","shell.execute_reply.started":"2023-09-28T15:43:55.731354Z","shell.execute_reply":"2023-09-28T15:43:55.749846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:43:55.752493Z","iopub.execute_input":"2023-09-28T15:43:55.753144Z","iopub.status.idle":"2023-09-28T15:43:55.827873Z","shell.execute_reply.started":"2023-09-28T15:43:55.753112Z","shell.execute_reply":"2023-09-28T15:43:55.826964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-generator')\ntokenizer = ElectraTokenizer.from_pretrained('/kaggle/input/electra/base-discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:43:55.829337Z","iopub.execute_input":"2023-09-28T15:43:55.829676Z","iopub.status.idle":"2023-09-28T15:43:55.892134Z","shell.execute_reply.started":"2023-09-28T15:43:55.829646Z","shell.execute_reply":"2023-09-28T15:43:55.891195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 512 #Use 512 for better results (if using GPU)\n\ndef tokenize_text(text):\n    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n\ndata['text_tokens'] = data['text'].apply(tokenize_text)\n\n# Split the data into features and targets\nX = data['text_tokens'].tolist()\ny = data[['wording', 'content']].values\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train).to(device)\nX_test = torch.tensor(X_test).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:43:55.895549Z","iopub.execute_input":"2023-09-28T15:43:55.895880Z","iopub.status.idle":"2023-09-28T15:44:18.970574Z","shell.execute_reply.started":"2023-09-28T15:43:55.895856Z","shell.execute_reply":"2023-09-28T15:44:18.969212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = ElectraModel.from_pretrained('google/electra-base-generator').to(device)\nbase_model = ElectraModel.from_pretrained('/kaggle/input/electra/base-discriminator').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:44:18.974663Z","iopub.execute_input":"2023-09-28T15:44:18.975789Z","iopub.status.idle":"2023-09-28T15:44:20.677133Z","shell.execute_reply.started":"2023-09-28T15:44:18.975746Z","shell.execute_reply":"2023-09-28T15:44:20.675908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_bert_embeddings(text_tokens):\n    embeddings_list = []\n    with tqdm(total=len(text_tokens)) as pbar:\n        with torch.no_grad():\n            for tokens in text_tokens:\n                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n                embeddings_list.append(embeddings)\n                pbar.update(1)\n        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n        return embeddings_tensor\n\nX_train_embeddings = generate_bert_embeddings(X_train)\nX_test_embeddings = generate_bert_embeddings(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:44:20.678635Z","iopub.execute_input":"2023-09-28T15:44:20.679745Z","iopub.status.idle":"2023-09-28T15:48:46.459561Z","shell.execute_reply.started":"2023-09-28T15:44:20.679708Z","shell.execute_reply":"2023-09-28T15:48:46.458334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RegressionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \n#Defining a MCRMSE\ndef mean_columnwise_rmse(y_pred, y_true):\n    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n    return torch.mean(columnwise_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:48:46.462060Z","iopub.execute_input":"2023-09-28T15:48:46.463574Z","iopub.status.idle":"2023-09-28T15:48:46.471594Z","shell.execute_reply.started":"2023-09-28T15:48:46.463535Z","shell.execute_reply":"2023-09-28T15:48:46.470324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = base_model.config.hidden_size\nhidden_dim = 256  # Adjust the hidden layer dimension as needed\noutput_dim = 2  # Number of target variables\nmodel = RegressionModel(input_dim, hidden_dim, output_dim).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 100 # Run it for 100-150 epoch\nbatch_size = 128 # 64 or 128 if using GPU\n\ntrain_dataset = TensorDataset(X_train_embeddings, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_loss1_list = []\ntrain_loss2_list = []\ntest_loss1_list = []\ntest_loss2_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:48:46.473175Z","iopub.execute_input":"2023-09-28T15:48:46.473621Z","iopub.status.idle":"2023-09-28T15:48:46.492030Z","shell.execute_reply.started":"2023-09-28T15:48:46.473554Z","shell.execute_reply":"2023-09-28T15:48:46.491070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss_wording = 0\n    total_loss_content = 0\n    total_loss = 0\n    \n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n        loss_content = criterion(outputs[:, 1], targets[:, 1])\n\n        loss = (loss_wording + loss_content) / 2\n        loss.backward()\n        optimizer.step()\n        \n        total_loss_wording += loss_wording.item()\n        total_loss_content += loss_content.item()\n\n        total_loss += loss.item()\n        \n    train_loss1_list.append(total_loss_wording / len(train_loader))\n    train_loss2_list.append(total_loss_content / len(train_loader))\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n    \n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(X_test_embeddings)\n        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n        \n    test_loss1_list.append(test_loss1.item())\n    test_loss2_list.append(test_loss2.item())\n    \n    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:48:46.493652Z","iopub.execute_input":"2023-09-28T15:48:46.494001Z","iopub.status.idle":"2023-09-28T15:49:01.208797Z","shell.execute_reply.started":"2023-09-28T15:48:46.493969Z","shell.execute_reply":"2023-09-28T15:49:01.207786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loss1_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.210404Z","iopub.execute_input":"2023-09-28T15:49:01.210800Z","iopub.status.idle":"2023-09-28T15:49:01.217368Z","shell.execute_reply.started":"2023-09-28T15:49:01.210763Z","shell.execute_reply":"2023-09-28T15:49:01.216384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_data = {\n    'Epoch': list(range(1, len(train_loss1_list)+1)),\n    'Train_Loss_Wording': train_loss1_list,\n    'Train_Loss_Content': train_loss2_list,\n    'Test_Loss_Wording': test_loss1_list,\n    'Test_Loss_Content': test_loss2_list\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.219352Z","iopub.execute_input":"2023-09-28T15:49:01.219994Z","iopub.status.idle":"2023-09-28T15:49:01.235760Z","shell.execute_reply.started":"2023-09-28T15:49:01.219958Z","shell.execute_reply":"2023-09-28T15:49:01.234805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df = pd.DataFrame(loss_data)\n# loss_df.to_csv('losses.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.237199Z","iopub.execute_input":"2023-09-28T15:49:01.237677Z","iopub.status.idle":"2023-09-28T15:49:01.248028Z","shell.execute_reply.started":"2023-09-28T15:49:01.237640Z","shell.execute_reply":"2023-09-28T15:49:01.247070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_data['text_tokens'] = test_data['text'].apply(tokenize_text)\ntest_text_tokens = test_data['text_tokens'].tolist()\ntest_text_tokens = torch.tensor(test_text_tokens).to(device)\ntest_data_embeddings = generate_bert_embeddings(test_text_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.252563Z","iopub.execute_input":"2023-09-28T15:49:01.252836Z","iopub.status.idle":"2023-09-28T15:49:01.435405Z","shell.execute_reply.started":"2023-09-28T15:49:01.252812Z","shell.execute_reply":"2023-09-28T15:49:01.434250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict scores for test data\nmodel.eval()  # Set the model in evaluation mode\nwith torch.no_grad():\n    test_outputs = model(test_data_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.436964Z","iopub.execute_input":"2023-09-28T15:49:01.437440Z","iopub.status.idle":"2023-09-28T15:49:01.443884Z","shell.execute_reply.started":"2023-09-28T15:49:01.437403Z","shell.execute_reply":"2023-09-28T15:49:01.442832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.445316Z","iopub.execute_input":"2023-09-28T15:49:01.446512Z","iopub.status.idle":"2023-09-28T15:49:01.470595Z","shell.execute_reply.started":"2023-09-28T15:49:01.446477Z","shell.execute_reply":"2023-09-28T15:49:01.469625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['student_id'] = test_data['student_id']\nsubmission_df['content'] = test_outputs[:, 1].cpu()\nsubmission_df['wording'] = test_outputs[:, 0].cpu()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.471971Z","iopub.execute_input":"2023-09-28T15:49:01.472530Z","iopub.status.idle":"2023-09-28T15:49:01.481683Z","shell.execute_reply.started":"2023-09-28T15:49:01.472498Z","shell.execute_reply":"2023-09-28T15:49:01.480593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:49:01.484013Z","iopub.execute_input":"2023-09-28T15:49:01.484941Z","iopub.status.idle":"2023-09-28T15:49:01.493619Z","shell.execute_reply.started":"2023-09-28T15:49:01.484907Z","shell.execute_reply":"2023-09-28T15:49:01.492504Z"},"trusted":true},"execution_count":null,"outputs":[]}]}