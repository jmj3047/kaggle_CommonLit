{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n# from transformers import BertTokenizer, BertModel\n# from transformers import ElectraTokenizer, ElectraModel\n\nfrom transformers import ElectraTokenizer, ElectraModel, ElectraForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm  # Import tqdm for the progress bar","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:10:39.526099Z","iopub.execute_input":"2023-09-28T14:10:39.526520Z","iopub.status.idle":"2023-09-28T14:10:39.533307Z","shell.execute_reply.started":"2023-09-28T14:10:39.526486Z","shell.execute_reply":"2023-09-28T14:10:39.532072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:10:39.858458Z","iopub.execute_input":"2023-09-28T14:10:39.859114Z","iopub.status.idle":"2023-09-28T14:10:39.864992Z","shell.execute_reply.started":"2023-09-28T14:10:39.859081Z","shell.execute_reply":"2023-09-28T14:10:39.863962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:10:40.026786Z","iopub.execute_input":"2023-09-28T14:10:40.027127Z","iopub.status.idle":"2023-09-28T14:10:40.081107Z","shell.execute_reply.started":"2023-09-28T14:10:40.027100Z","shell.execute_reply":"2023-09-28T14:10:40.080213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-generator')\ntokenizer = ElectraTokenizer.from_pretrained('/kaggle/input/electra/base-discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:10:40.177090Z","iopub.execute_input":"2023-09-28T14:10:40.177958Z","iopub.status.idle":"2023-09-28T14:10:40.232087Z","shell.execute_reply.started":"2023-09-28T14:10:40.177923Z","shell.execute_reply":"2023-09-28T14:10:40.231203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 512 #Use 512 for better results (if using GPU)\n\ndef tokenize_text(text):\n    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n\ndata['text_tokens'] = data['text'].apply(tokenize_text)\n\n# Split the data into features and targets\nX = data['text_tokens'].tolist()\ny = data[['wording', 'content']].values\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train).to(device)\nX_test = torch.tensor(X_test).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:10:40.294947Z","iopub.execute_input":"2023-09-28T14:10:40.295567Z","iopub.status.idle":"2023-09-28T14:11:04.306193Z","shell.execute_reply.started":"2023-09-28T14:10:40.295515Z","shell.execute_reply":"2023-09-28T14:11:04.305184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = ElectraModel.from_pretrained('google/electra-base-generator').to(device)\nbase_model = ElectraModel.from_pretrained('/kaggle/input/electra/base-discriminator').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:11:04.308484Z","iopub.execute_input":"2023-09-28T14:11:04.308936Z","iopub.status.idle":"2023-09-28T14:11:05.968069Z","shell.execute_reply.started":"2023-09-28T14:11:04.308902Z","shell.execute_reply":"2023-09-28T14:11:05.966980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_bert_embeddings(text_tokens):\n    embeddings_list = []\n    with tqdm(total=len(text_tokens)) as pbar:\n        with torch.no_grad():\n            for tokens in text_tokens:\n                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n                embeddings_list.append(embeddings)\n                pbar.update(1)\n        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n        return embeddings_tensor\n\nX_train_embeddings = generate_bert_embeddings(X_train)\nX_test_embeddings = generate_bert_embeddings(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:11:05.969649Z","iopub.execute_input":"2023-09-28T14:11:05.971966Z","iopub.status.idle":"2023-09-28T14:15:31.343296Z","shell.execute_reply.started":"2023-09-28T14:11:05.971927Z","shell.execute_reply":"2023-09-28T14:15:31.342076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RegressionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \n#Defining a MCRMSE\ndef mean_columnwise_rmse(y_pred, y_true):\n    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n    return torch.mean(columnwise_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:31.347530Z","iopub.execute_input":"2023-09-28T14:15:31.348458Z","iopub.status.idle":"2023-09-28T14:15:31.359526Z","shell.execute_reply.started":"2023-09-28T14:15:31.348417Z","shell.execute_reply":"2023-09-28T14:15:31.358313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = base_model.config.hidden_size\nhidden_dim = 256  # Adjust the hidden layer dimension as needed\noutput_dim = 2  # Number of target variables\nmodel = RegressionModel(input_dim, hidden_dim, output_dim).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 100 # Run it for 100-150 epoch\nbatch_size = 128 # 64 or 128 if using GPU\n\ntrain_dataset = TensorDataset(X_train_embeddings, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_loss1_list = []\ntrain_loss2_list = []\ntest_loss1_list = []\ntest_loss2_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:31.360900Z","iopub.execute_input":"2023-09-28T14:15:31.361547Z","iopub.status.idle":"2023-09-28T14:15:31.380548Z","shell.execute_reply.started":"2023-09-28T14:15:31.361506Z","shell.execute_reply":"2023-09-28T14:15:31.379749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss_wording = 0\n    total_loss_content = 0\n    total_loss = 0\n    \n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n        loss_content = criterion(outputs[:, 1], targets[:, 1])\n\n        loss = (loss_wording + loss_content) / 2\n        loss.backward()\n        optimizer.step()\n        \n        total_loss_wording += loss_wording.item()\n        total_loss_content += loss_content.item()\n\n        total_loss += loss.item()\n        \n    train_loss1_list.append(total_loss_wording / len(train_loader))\n    train_loss2_list.append(total_loss_content / len(train_loader))\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n    \n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(X_test_embeddings)\n        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n        \n    test_loss1_list.append(test_loss1.item())\n    test_loss2_list.append(test_loss2.item())\n    \n    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:31.381746Z","iopub.execute_input":"2023-09-28T14:15:31.382646Z","iopub.status.idle":"2023-09-28T14:15:45.638928Z","shell.execute_reply.started":"2023-09-28T14:15:31.382613Z","shell.execute_reply":"2023-09-28T14:15:45.637133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loss1_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.640948Z","iopub.execute_input":"2023-09-28T14:15:45.641893Z","iopub.status.idle":"2023-09-28T14:15:45.650163Z","shell.execute_reply.started":"2023-09-28T14:15:45.641847Z","shell.execute_reply":"2023-09-28T14:15:45.648578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_data = {\n    'Epoch': list(range(1, len(train_loss1_list)+1)),\n    'Train_Loss_Wording': train_loss1_list,\n    'Train_Loss_Content': train_loss2_list,\n    'Test_Loss_Wording': test_loss1_list,\n    'Test_Loss_Content': test_loss2_list\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.652447Z","iopub.execute_input":"2023-09-28T14:15:45.653553Z","iopub.status.idle":"2023-09-28T14:15:45.660942Z","shell.execute_reply.started":"2023-09-28T14:15:45.653514Z","shell.execute_reply":"2023-09-28T14:15:45.659733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df = pd.DataFrame(loss_data)\n# loss_df.to_csv('losses.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.663319Z","iopub.execute_input":"2023-09-28T14:15:45.664177Z","iopub.status.idle":"2023-09-28T14:15:45.686009Z","shell.execute_reply.started":"2023-09-28T14:15:45.664140Z","shell.execute_reply":"2023-09-28T14:15:45.683647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_data['text_tokens'] = test_data['text'].apply(tokenize_text)\ntest_text_tokens = test_data['text_tokens'].tolist()\ntest_text_tokens = torch.tensor(test_text_tokens).to(device)\ntest_data_embeddings = generate_bert_embeddings(test_text_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.692129Z","iopub.execute_input":"2023-09-28T14:15:45.692838Z","iopub.status.idle":"2023-09-28T14:15:45.897596Z","shell.execute_reply.started":"2023-09-28T14:15:45.692808Z","shell.execute_reply":"2023-09-28T14:15:45.896684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict scores for test data\nmodel.eval()  # Set the model in evaluation mode\nwith torch.no_grad():\n    test_outputs = model(test_data_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.902584Z","iopub.execute_input":"2023-09-28T14:15:45.903350Z","iopub.status.idle":"2023-09-28T14:15:45.912898Z","shell.execute_reply.started":"2023-09-28T14:15:45.903305Z","shell.execute_reply":"2023-09-28T14:15:45.912032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:15:45.914804Z","iopub.execute_input":"2023-09-28T14:15:45.915583Z","iopub.status.idle":"2023-09-28T14:15:45.929287Z","shell.execute_reply.started":"2023-09-28T14:15:45.915548Z","shell.execute_reply":"2023-09-28T14:15:45.928309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['student_id'] = test_data['student_id']\nsubmission_df['content'] = test_outputs[:, 1].cpu()\nsubmission_df['wording'] = test_outputs[:, 0].cpu()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:16:09.997677Z","iopub.execute_input":"2023-09-28T14:16:09.998046Z","iopub.status.idle":"2023-09-28T14:16:10.009180Z","shell.execute_reply.started":"2023-09-28T14:16:09.998016Z","shell.execute_reply":"2023-09-28T14:16:10.007656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}