{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-28T12:40:05.816286Z","iopub.execute_input":"2023-09-28T12:40:05.816540Z","iopub.status.idle":"2023-09-28T12:40:06.908229Z","shell.execute_reply.started":"2023-09-28T12:40:05.816514Z","shell.execute_reply":"2023-09-28T12:40:06.906718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n# from transformers import BertTokenizer, BertModel\n# from transformers import ElectraTokenizer, ElectraModel\n\nfrom transformers import ElectraTokenizer, ElectraModel, ElectraForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm  # Import tqdm for the progress bar","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:40:08.979898Z","iopub.execute_input":"2023-09-28T12:40:08.980391Z","iopub.status.idle":"2023-09-28T12:40:23.863880Z","shell.execute_reply.started":"2023-09-28T12:40:08.980351Z","shell.execute_reply":"2023-09-28T12:40:23.862744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:40:23.865738Z","iopub.execute_input":"2023-09-28T12:40:23.866147Z","iopub.status.idle":"2023-09-28T12:40:23.934853Z","shell.execute_reply.started":"2023-09-28T12:40:23.866114Z","shell.execute_reply":"2023-09-28T12:40:23.932870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:41:17.272043Z","iopub.execute_input":"2023-09-28T12:41:17.272835Z","iopub.status.idle":"2023-09-28T12:41:17.454416Z","shell.execute_reply.started":"2023-09-28T12:41:17.272797Z","shell.execute_reply":"2023-09-28T12:41:17.453407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-generator')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:41:29.539322Z","iopub.execute_input":"2023-09-28T12:41:29.539693Z","iopub.status.idle":"2023-09-28T12:41:30.171648Z","shell.execute_reply.started":"2023-09-28T12:41:29.539663Z","shell.execute_reply":"2023-09-28T12:41:30.170639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 512 #Use 512 for better results (if using GPU)\n\ndef tokenize_text(text):\n    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n\ndata['text_tokens'] = data['text'].apply(tokenize_text)\n\n# Split the data into features and targets\nX = data['text_tokens'].tolist()\ny = data[['wording', 'content']].values\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train).to(device)\nX_test = torch.tensor(X_test).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:41:36.469616Z","iopub.execute_input":"2023-09-28T12:41:36.470216Z","iopub.status.idle":"2023-09-28T12:42:08.879932Z","shell.execute_reply.started":"2023-09-28T12:41:36.470141Z","shell.execute_reply":"2023-09-28T12:42:08.878978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = ElectraModel.from_pretrained('google/electra-base-generator').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:42:19.531819Z","iopub.execute_input":"2023-09-28T12:42:19.532252Z","iopub.status.idle":"2023-09-28T12:42:25.294367Z","shell.execute_reply.started":"2023-09-28T12:42:19.532194Z","shell.execute_reply":"2023-09-28T12:42:25.293239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_bert_embeddings(text_tokens):\n    embeddings_list = []\n    with tqdm(total=len(text_tokens)) as pbar:\n        with torch.no_grad():\n            for tokens in text_tokens:\n                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n                embeddings_list.append(embeddings)\n                pbar.update(1)\n        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n        return embeddings_tensor\n\nX_train_embeddings = generate_bert_embeddings(X_train)\nX_test_embeddings = generate_bert_embeddings(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:42:35.959526Z","iopub.execute_input":"2023-09-28T12:42:35.960358Z","iopub.status.idle":"2023-09-28T12:44:14.338200Z","shell.execute_reply.started":"2023-09-28T12:42:35.960286Z","shell.execute_reply":"2023-09-28T12:44:14.337085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RegressionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \n#Defining a MCRMSE\ndef mean_columnwise_rmse(y_pred, y_true):\n    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n    return torch.mean(columnwise_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:23.057421Z","iopub.execute_input":"2023-09-28T12:44:23.057800Z","iopub.status.idle":"2023-09-28T12:44:23.066627Z","shell.execute_reply.started":"2023-09-28T12:44:23.057770Z","shell.execute_reply":"2023-09-28T12:44:23.065438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = base_model.config.hidden_size\nhidden_dim = 256  # Adjust the hidden layer dimension as needed\noutput_dim = 2  # Number of target variables\nmodel = RegressionModel(input_dim, hidden_dim, output_dim).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 125 # Run it for 100-150 epoch\nbatch_size = 128 # 64 or 128 if using GPU\n\ntrain_dataset = TensorDataset(X_train_embeddings, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_loss1_list = []\ntrain_loss2_list = []\ntest_loss1_list = []\ntest_loss2_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:25.531910Z","iopub.execute_input":"2023-09-28T12:44:25.532340Z","iopub.status.idle":"2023-09-28T12:44:25.543544Z","shell.execute_reply.started":"2023-09-28T12:44:25.532305Z","shell.execute_reply":"2023-09-28T12:44:25.542469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss_wording = 0\n    total_loss_content = 0\n    total_loss = 0\n    \n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n        loss_content = criterion(outputs[:, 1], targets[:, 1])\n\n        loss = (loss_wording + loss_content) / 2\n        loss.backward()\n        optimizer.step()\n        \n        total_loss_wording += loss_wording.item()\n        total_loss_content += loss_content.item()\n\n        total_loss += loss.item()\n        \n    train_loss1_list.append(total_loss_wording / len(train_loader))\n    train_loss2_list.append(total_loss_content / len(train_loader))\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n    \n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(X_test_embeddings)\n        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n        \n    test_loss1_list.append(test_loss1.item())\n    test_loss2_list.append(test_loss2.item())\n    \n    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:27.413952Z","iopub.execute_input":"2023-09-28T12:44:27.414329Z","iopub.status.idle":"2023-09-28T12:44:35.187953Z","shell.execute_reply.started":"2023-09-28T12:44:27.414294Z","shell.execute_reply":"2023-09-28T12:44:35.186889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_data = {\n    'Epoch': list(range(1, num_epochs+1)),\n    'Train_Loss_Wording': train_loss1_list,\n    'Train_Loss_Content': train_loss2_list,\n    'Test_Loss_Wording': test_loss1_list,\n    'Test_Loss_Content': test_loss2_list\n}\n\nloss_df = pd.DataFrame(loss_data)\nloss_df.to_csv('losses.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:39.058846Z","iopub.execute_input":"2023-09-28T12:44:39.059226Z","iopub.status.idle":"2023-09-28T12:44:39.070600Z","shell.execute_reply.started":"2023-09-28T12:44:39.059188Z","shell.execute_reply":"2023-09-28T12:44:39.069462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_data['text_tokens'] = test_data['text'].apply(tokenize_text)\ntest_text_tokens = test_data['text_tokens'].tolist()\ntest_text_tokens = torch.tensor(test_text_tokens).to(device)\ntest_data_embeddings = generate_bert_embeddings(test_text_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:41.510134Z","iopub.execute_input":"2023-09-28T12:44:41.510663Z","iopub.status.idle":"2023-09-28T12:44:41.619226Z","shell.execute_reply.started":"2023-09-28T12:44:41.510631Z","shell.execute_reply":"2023-09-28T12:44:41.618218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict scores for test data\nmodel.eval()  # Set the model in evaluation mode\nwith torch.no_grad():\n    test_outputs = model(test_data_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:44.284251Z","iopub.execute_input":"2023-09-28T12:44:44.284637Z","iopub.status.idle":"2023-09-28T12:44:44.290303Z","shell.execute_reply.started":"2023-09-28T12:44:44.284602Z","shell.execute_reply":"2023-09-28T12:44:44.289256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:45.669061Z","iopub.execute_input":"2023-09-28T12:44:45.669780Z","iopub.status.idle":"2023-09-28T12:44:45.696715Z","shell.execute_reply.started":"2023-09-28T12:44:45.669744Z","shell.execute_reply":"2023-09-28T12:44:45.695655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['student_id'] = test_data['student_id']\nsubmission_df['content'] = test_outputs[:, 1].cpu()\nsubmission_df['wording'] = test_outputs[:, 0].cpu()\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:48.679422Z","iopub.execute_input":"2023-09-28T12:44:48.679865Z","iopub.status.idle":"2023-09-28T12:44:48.693289Z","shell.execute_reply.started":"2023-09-28T12:44:48.679827Z","shell.execute_reply":"2023-09-28T12:44:48.692203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:44:56.966884Z","iopub.execute_input":"2023-09-28T12:44:56.967317Z","iopub.status.idle":"2023-09-28T12:44:56.984378Z","shell.execute_reply.started":"2023-09-28T12:44:56.967281Z","shell.execute_reply":"2023-09-28T12:44:56.983326Z"},"trusted":true},"execution_count":null,"outputs":[]}]}