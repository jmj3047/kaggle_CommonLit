{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-28T12:40:05.816286Z","iopub.execute_input":"2023-09-28T12:40:05.816540Z","iopub.status.idle":"2023-09-28T12:40:06.908229Z","shell.execute_reply.started":"2023-09-28T12:40:05.816514Z","shell.execute_reply":"2023-09-28T12:40:06.906718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n# from transformers import BertTokenizer, BertModel\n# from transformers import ElectraTokenizer, ElectraModel\n\nfrom transformers import ElectraTokenizer, ElectraModel, ElectraForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm  # Import tqdm for the progress bar","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:07:21.637706Z","iopub.execute_input":"2023-09-28T13:07:21.638528Z","iopub.status.idle":"2023-09-28T13:07:45.607833Z","shell.execute_reply.started":"2023-09-28T13:07:21.638494Z","shell.execute_reply":"2023-09-28T13:07:45.606623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:08:09.991108Z","iopub.execute_input":"2023-09-28T13:08:09.991486Z","iopub.status.idle":"2023-09-28T13:08:10.062696Z","shell.execute_reply.started":"2023-09-28T13:08:09.991455Z","shell.execute_reply":"2023-09-28T13:08:10.061703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:08:13.300428Z","iopub.execute_input":"2023-09-28T13:08:13.300834Z","iopub.status.idle":"2023-09-28T13:08:13.433870Z","shell.execute_reply.started":"2023-09-28T13:08:13.300804Z","shell.execute_reply":"2023-09-28T13:08:13.432861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-generator')\ntokenizer = ElectraTokenizer.from_pretrained('/kaggle/input/electra/base-discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:14:53.940287Z","iopub.execute_input":"2023-09-28T13:14:53.940692Z","iopub.status.idle":"2023-09-28T13:14:54.029302Z","shell.execute_reply.started":"2023-09-28T13:14:53.940662Z","shell.execute_reply":"2023-09-28T13:14:54.028326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 512 #Use 512 for better results (if using GPU)\n\ndef tokenize_text(text):\n    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n\ndata['text_tokens'] = data['text'].apply(tokenize_text)\n\n# Split the data into features and targets\nX = data['text_tokens'].tolist()\ny = data[['wording', 'content']].values\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train).to(device)\nX_test = torch.tensor(X_test).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:14:58.521935Z","iopub.execute_input":"2023-09-28T13:14:58.522322Z","iopub.status.idle":"2023-09-28T13:15:29.942428Z","shell.execute_reply.started":"2023-09-28T13:14:58.522261Z","shell.execute_reply":"2023-09-28T13:15:29.941173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = ElectraModel.from_pretrained('google/electra-base-generator').to(device)\nbase_model = ElectraModel.from_pretrained('/kaggle/input/electra/base-discriminator').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:15:32.760350Z","iopub.execute_input":"2023-09-28T13:15:32.760726Z","iopub.status.idle":"2023-09-28T13:15:39.341435Z","shell.execute_reply.started":"2023-09-28T13:15:32.760698Z","shell.execute_reply":"2023-09-28T13:15:39.340158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_bert_embeddings(text_tokens):\n    embeddings_list = []\n    with tqdm(total=len(text_tokens)) as pbar:\n        with torch.no_grad():\n            for tokens in text_tokens:\n                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n                embeddings_list.append(embeddings)\n                pbar.update(1)\n        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n        return embeddings_tensor\n\nX_train_embeddings = generate_bert_embeddings(X_train)\nX_test_embeddings = generate_bert_embeddings(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:15:58.950429Z","iopub.execute_input":"2023-09-28T13:15:58.950783Z","iopub.status.idle":"2023-09-28T13:20:22.771664Z","shell.execute_reply.started":"2023-09-28T13:15:58.950754Z","shell.execute_reply":"2023-09-28T13:20:22.770702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RegressionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \n#Defining a MCRMSE\ndef mean_columnwise_rmse(y_pred, y_true):\n    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n    return torch.mean(columnwise_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:45:58.018340Z","iopub.execute_input":"2023-09-28T13:45:58.018701Z","iopub.status.idle":"2023-09-28T13:45:58.026366Z","shell.execute_reply.started":"2023-09-28T13:45:58.018672Z","shell.execute_reply":"2023-09-28T13:45:58.025464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = base_model.config.hidden_size\nhidden_dim = 256  # Adjust the hidden layer dimension as needed\noutput_dim = 2  # Number of target variables\nmodel = RegressionModel(input_dim, hidden_dim, output_dim).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 100 # Run it for 100-150 epoch\nbatch_size = 128 # 64 or 128 if using GPU\n\ntrain_dataset = TensorDataset(X_train_embeddings, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntrain_loss1_list = []\ntrain_loss2_list = []\ntest_loss1_list = []\ntest_loss2_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:29.737939Z","iopub.execute_input":"2023-09-28T13:48:29.738324Z","iopub.status.idle":"2023-09-28T13:48:29.757427Z","shell.execute_reply.started":"2023-09-28T13:48:29.738290Z","shell.execute_reply":"2023-09-28T13:48:29.756250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss_wording = 0\n    total_loss_content = 0\n    total_loss = 0\n    \n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n        loss_content = criterion(outputs[:, 1], targets[:, 1])\n\n        loss = (loss_wording + loss_content) / 2\n        loss.backward()\n        optimizer.step()\n        \n        total_loss_wording += loss_wording.item()\n        total_loss_content += loss_content.item()\n\n        total_loss += loss.item()\n        \n    train_loss1_list.append(total_loss_wording / len(train_loader))\n    train_loss2_list.append(total_loss_content / len(train_loader))\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n    \n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(X_test_embeddings)\n        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n        \n    test_loss1_list.append(test_loss1.item())\n    test_loss2_list.append(test_loss2.item())\n    \n    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:29.888026Z","iopub.execute_input":"2023-09-28T13:48:29.888366Z","iopub.status.idle":"2023-09-28T13:48:53.884334Z","shell.execute_reply.started":"2023-09-28T13:48:29.888339Z","shell.execute_reply":"2023-09-28T13:48:53.883398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loss1_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:53.886165Z","iopub.execute_input":"2023-09-28T13:48:53.886783Z","iopub.status.idle":"2023-09-28T13:48:53.893776Z","shell.execute_reply.started":"2023-09-28T13:48:53.886746Z","shell.execute_reply":"2023-09-28T13:48:53.892745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_data = {\n    'Epoch': list(range(1, len(train_loss1_list)+1)),\n    'Train_Loss_Wording': train_loss1_list,\n    'Train_Loss_Content': train_loss2_list,\n    'Test_Loss_Wording': test_loss1_list,\n    'Test_Loss_Content': test_loss2_list\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:53.895160Z","iopub.execute_input":"2023-09-28T13:48:53.895580Z","iopub.status.idle":"2023-09-28T13:48:53.904809Z","shell.execute_reply.started":"2023-09-28T13:48:53.895543Z","shell.execute_reply":"2023-09-28T13:48:53.903836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df = pd.DataFrame(loss_data)\nloss_df.to_csv('losses.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:53.907593Z","iopub.execute_input":"2023-09-28T13:48:53.907990Z","iopub.status.idle":"2023-09-28T13:48:53.921863Z","shell.execute_reply.started":"2023-09-28T13:48:53.907955Z","shell.execute_reply":"2023-09-28T13:48:53.920794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_data['text_tokens'] = test_data['text'].apply(tokenize_text)\ntest_text_tokens = test_data['text_tokens'].tolist()\ntest_text_tokens = torch.tensor(test_text_tokens).to(device)\ntest_data_embeddings = generate_bert_embeddings(test_text_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:53.925136Z","iopub.execute_input":"2023-09-28T13:48:53.925450Z","iopub.status.idle":"2023-09-28T13:48:54.100608Z","shell.execute_reply.started":"2023-09-28T13:48:53.925424Z","shell.execute_reply":"2023-09-28T13:48:54.099583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict scores for test data\nmodel.eval()  # Set the model in evaluation mode\nwith torch.no_grad():\n    test_outputs = model(test_data_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:54.102124Z","iopub.execute_input":"2023-09-28T13:48:54.103034Z","iopub.status.idle":"2023-09-28T13:48:54.108967Z","shell.execute_reply.started":"2023-09-28T13:48:54.102994Z","shell.execute_reply":"2023-09-28T13:48:54.107648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:54.110769Z","iopub.execute_input":"2023-09-28T13:48:54.111132Z","iopub.status.idle":"2023-09-28T13:48:54.125176Z","shell.execute_reply.started":"2023-09-28T13:48:54.111099Z","shell.execute_reply":"2023-09-28T13:48:54.124308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['student_id'] = test_data['student_id']\nsubmission_df['content'] = test_outputs[:, 1].cpu()\nsubmission_df['wording'] = test_outputs[:, 0].cpu()\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:54.126699Z","iopub.execute_input":"2023-09-28T13:48:54.127482Z","iopub.status.idle":"2023-09-28T13:48:54.137844Z","shell.execute_reply.started":"2023-09-28T13:48:54.127446Z","shell.execute_reply":"2023-09-28T13:48:54.136741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:48:54.139485Z","iopub.execute_input":"2023-09-28T13:48:54.140072Z","iopub.status.idle":"2023-09-28T13:48:54.155418Z","shell.execute_reply.started":"2023-09-28T13:48:54.140037Z","shell.execute_reply":"2023-09-28T13:48:54.154323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}